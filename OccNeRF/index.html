<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="OccNeRF: Self-Supervised Multi-Camera Occupancy Prediction with Neural Radiance Fields.">
  <meta name="keywords" content="OccNeRF, occupancy, self-supervise">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>OccNeRF: Self-Supervised Multi-Camera Occupancy Prediction with Neural Radiance Fields</title>
 
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>



<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">OccNeRF: Self-Supervised Multi-Camera Occupancy Prediction with Neural Radiance Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/LinShan-Bin">Chubin Zhang</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://github.com/JunchengYan">Juncheng Yan</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://weiyithu.github.io/">Yi Wei</a><sup>1,2*</sup>,</span>
             <br>
            <span class="author-block">
              <a href="https://www.jiaxinli.me/">Jiaxin Li</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://github">Li Liu</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://andytang15.github.io/">Yansong Tang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://duanyueqi.github.io/">Yueqi Duan</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://ivg.au.tsinghua.edu.cn/Jiwen_Lu/">Jiwen Lu</a><sup>1,2</sup>
            </span>
          </div>

          <div align="center" style="margin-bottom:20px;">
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University &nbsp;&nbsp;</span>
            <span class="author-block"><sup>2</sup>Beijing National Research Center for Information Science and Technology &nbsp;&nbsp;</span>
            <br>
            <span class="author-block"><sup>3</sup>Gaussian Robotics &nbsp;&nbsp;</span>
            <span class="author-block"><sup>4</sup>Xiaomi Car &nbsp;&nbsp;</span>
          </div>
          </div>

          <!-- <h1 style="font-size:24px;font-weight:bold">arXiv</h1>
          <div class="column has-text-centered"> -->
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="static/2312.09243.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2312.09243"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/LinShan-Bin/OccNeRF"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 align="center"  class="title is-3">Demo</h2>

        <h3 align="center" class="title is-4">Depth Estimation </h3>
        <div class="content has-text-justified">
        </div>
        <div class="content has-text-centered">
          <video poster='static/images/occnerf-demo-0.png'
                 id="replay-video"
                 controls
                 muted
                 width="50%">
            <source src="static/videos/occnerf-demo.mp4"
                    type="video/mp4">
          </video>
        </div>


        <h3 align="center" class="title is-4">3D Occupancy Prediction </h3>
        <div class="content has-text-justified">
        </div>
        <div class="content has-text-centered">
          <video poster='static/images/occnerf-demo-sem-0.png'
                 id="replay-video"
                 controls
                 muted
                 width="50%">
                 <source src="static/videos/occnerf-demo-sem.mp4"
                    type="video/mp4">
          </video>
        </div>
          
        
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">

    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            As a fundamental task of vision-based perception, 3D occupancy prediction reconstructs 3D structures of surrounding environments. 
            It provides detailed information for autonomous driving planning and navigation. 
            However, most existing methods heavily rely on the LiDAR point clouds to generate occupancy ground truth, 
            which is not available in the vision-based system. 
            In this paper, we propose an OccNeRF method for <b>self-supervised multi-camera occupancy prediction</b>. 
            Different from bounded 3D occupancy labels, we need to consider unbounded scenes with raw image supervision. 
            To solve the issue, we parameterize the reconstructed occupancy fields and reorganize the sampling strategy. 
            The neural rendering is adopted to convert occupancy fields to multi-camera depth maps, supervised by multi-frame photometric consistency.  
            Moreover, for semantic occupancy prediction, we design several strategies to polish the prompts and filter the outputs of a pretrained open-vocabulary 2D segmentation model. 
            Extensive experiments for both self-supervised depth estimation and semantic occupancy prediction tasks on nuScenes dataset demonstrate the effectiveness of our method.
          </p>

        </div>
      </div>
    </div>
  </div>

<div align="center" style="margin-top:40px;" style="margin-bottom:80px;">
<img style='height: auto; width:40%; object-fit: contain' src="static/images/overview.jpg" alt="overview_image">
</div> 


<section class="section">
  <div class="container">

    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            The picture below is a brief summary of our method. We first use a 2D backbone to extract multi-camera features, which are lifted to 3D space to get volume
            features with interpolation. The <b>parameterized occupancy fields</b> are reconstructed to describe <b>unbounded scenes</b>. To obtain the rendered
            depth and semantic maps, we perform volume rendering with our <b>reorganized sampling strategy</b>. The multi-frame depths are supervised
            by photometric loss. For semantic prediction, we adopted pretrained Grounded-SAM with prompts cleaning. The green arrow indicates
            supervision signals.
          </p>

        </div>
      </div>
    </div>
  </div>

<div align="center" style="margin-top:40px;" style="margin-bottom:80px;">
<img style='height: auto; width:60%; object-fit: contain' src="static/images/pipeline.jpg" alt="overview_image">
</div>


<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 align="center"  class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p>
            We conducted self-supervised multi-camera depth estimation and 3D occupancy prediction on nuScenes dataset. Our method does not need any 3D supervision in both tasks.
          </p>
        </div>


        <h3 align="center" class="title is-4">Depth Estimation </h3>

        <div class="content has-text-justified">
          The following table shows the self-supervised multi-camera depth estimation results on nuScenes dataset. 
          We do not use pretrained segmentation model in this experiment. 
          The results are averaged over 6 cameras and ‘FSM*’ is the reproduced FSM result reported in VFDepth. 
          We can see that our method outperforms other state-of-the-art methods by a
          large margin, demonstrating the effectiveness of OccNeRF.
        </div>

        <img style='height: auto; width:100%; object-fit: contain' src="static/images/tab-de.png" alt="depth-estimation-results">

        <div class="content has-text-justified">
          The image below shows qualitative results on nuScenes dataset. Our method can predict visually appealing depth maps with texture details and fine-grained occupancy.
        </div>

        <img style='height: auto; width:100%; object-fit: contain' src="static/images/fig-de.png" alt="depth-estimation-qual-results">


        <div align="center" style="margin-top:40px;">
        <h3 align="center" class="title is-4">3D Occpancy Prediction </h3>

        <div class="content has-text-justified">
          We also conduct semantic occupancy prediction experiments on the Occ3D-nuScenes dataset. 
          Since the pretrained openvocabulary model cannot recognize ambiguous
          prompts such as ‘other’ and ‘other flat’, we remove these
          two classes during evaluation. For another self-supervised
          method SimpleOcc, we use the same 2D semantic labels from the pretrained model for fair comparison. 
          As shown in the following table, our method outperforms SimpleOcc and even gets comparable performance with
          some full-supervised methods in some classes.
        </div>

        <img style='height: auto; width:100%; object-fit: contain' src="static/images/tab-op.png" alt="occupancy-prediction-results">

        <div class="content has-text-justified">
          The image below shows qualitative results of semantic occupancy prediction from our model.
        </div>

        <img style='height: auto; width:100%; object-fit: contain' src="static/images/fig-op.png" alt="occupancy-prediction-qual-results">

      </div>
    </div>
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@article{zhang2025occnerf,
  title={Occnerf: Advancing 3d occupancy prediction in lidar-free environments},
  author={Zhang, Chubin and Yan, Juncheng and Wei, Yi and Li, Jiaxin and Liu, Li and Tang, Yansong and Duan, Yueqi and Lu, Jiwen},
  journal={IEEE Transactions on Image Processing},
  year={2025},
  publisher={IEEE}
}
</code></pre>
  </div>
</section>
    

<footer class="footer">
  <div align="center" class="container">
    <div class="columns is-centered">
        <div class="content">
            This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
        </div>
      </div>
    </div>
</footer>

</body>
</html>
